{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T15:10:01.766013Z","iopub.status.busy":"2023-09-24T15:10:01.765366Z","iopub.status.idle":"2023-09-24T15:10:01.772400Z","shell.execute_reply":"2023-09-24T15:10:01.771384Z","shell.execute_reply.started":"2023-09-24T15:10:01.765977Z"},"trusted":true},"outputs":[],"source":["import transformers\n","import torch\n","import random\n","import numpy as np\n","from torch.utils.data import random_split\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from transformers import GenerationConfig\n","\n","import sys\n","if '..' not in sys.path: sys.path.append('..')\n","from src.data.make_dataset import load_detoxification_dataset, load_toxicity_dataset"]},{"cell_type":"markdown","metadata":{},"source":["# Load the pretrained T5"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["global_seed = 1984\n","\n","transformers.set_seed(global_seed)\n","random.seed(global_seed)\n","np.random.seed(global_seed)\n","torch.manual_seed(global_seed)\n","torch.cuda.manual_seed_all(global_seed)\n","model_checkpoint = \"t5-small\""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n","dataset_portion = 1\n","dataset_kwargs = {\n","    'path': '../data/raw/filtered.tsv', # path to raw data\n","    'cache_path': '../data/interim/tokenized.tsv', # path to processed data (or where to store it)\n","    'tokenizer': tokenizer, # tokenizer to tokenize texts\n","    'portion': dataset_portion # get only a portion of dataset [0..1]\n","}"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["dataset = load_detoxification_dataset(**dataset_kwargs)\n","\n","val_ratio = 0.2\n","train_dataset, val_dataset = random_split(dataset, [1 - val_ratio, val_ratio])"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# defining the parameters for training\n","genConfig = GenerationConfig.from_pretrained(model_checkpoint)\n","genConfig.max_new_tokens = 64\n","\n","batch_size = 32\n","postfix = \"-10\"\n","save_model_path = f'../models/t5_detoxifier{postfix}x10lr'\n","args = Seq2SeqTrainingArguments(\n","    f\"../models/{model_checkpoint}-detoxification{postfix}x10lr\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=5e-4,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=10,\n","    num_train_epochs=20,\n","    predict_with_generate=True,\n","    fp16=True,\n","    report_to='tensorboard',\n","    logging_steps=5000,\n","    save_steps=25000,\n","    generation_config=genConfig\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=collator,\n","    tokenizer=tokenizer,\n","    # compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f76a7f6cfb2141ad88491c205135bacd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/288900 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 1.96, 'learning_rate': 0.00049134994807892, 'epoch': 0.35}\n","{'loss': 1.8517, 'learning_rate': 0.0004826998961578401, 'epoch': 0.69}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48e752601a9e4333b813be8a84c0c229","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.6692404747009277, 'eval_runtime': 112.3317, 'eval_samples_per_second': 1028.694, 'eval_steps_per_second': 32.155, 'epoch': 1.0}\n","{'loss': 1.8016, 'learning_rate': 0.0004740515749394254, 'epoch': 1.04}\n","{'loss': 1.7309, 'learning_rate': 0.0004654015230183455, 'epoch': 1.38}\n","{'loss': 1.7211, 'learning_rate': 0.0004567532017999308, 'epoch': 1.73}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9eec886f0bb24342bc793cc8646b34fa","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.6123136281967163, 'eval_runtime': 111.5584, 'eval_samples_per_second': 1035.826, 'eval_steps_per_second': 32.378, 'epoch': 2.0}\n","{'loss': 1.6984, 'learning_rate': 0.00044810488058151613, 'epoch': 2.08}\n","{'loss': 1.6463, 'learning_rate': 0.0004394548286604361, 'epoch': 2.42}\n","{'loss': 1.6487, 'learning_rate': 0.0004308047767393562, 'epoch': 2.77}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"016b387c9b584ffd87b40211cb264242","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.582676649093628, 'eval_runtime': 111.5176, 'eval_samples_per_second': 1036.204, 'eval_steps_per_second': 32.39, 'epoch': 3.0}\n","{'loss': 1.6257, 'learning_rate': 0.0004221564555209415, 'epoch': 3.12}\n","{'loss': 1.588, 'learning_rate': 0.00041350640359986155, 'epoch': 3.46}\n","{'loss': 1.5958, 'learning_rate': 0.0004048580823814469, 'epoch': 3.81}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b67df2fb2df4c618a47cede46ba8e1e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5665289163589478, 'eval_runtime': 111.5714, 'eval_samples_per_second': 1035.704, 'eval_steps_per_second': 32.374, 'epoch': 4.0}\n","{'loss': 1.5674, 'learning_rate': 0.0003962080304603669, 'epoch': 4.15}\n","{'loss': 1.5437, 'learning_rate': 0.000387557978539287, 'epoch': 4.5}\n","{'loss': 1.5541, 'learning_rate': 0.0003789096573208723, 'epoch': 4.85}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"908393521c1645d8903c9f6bc9cd7a26","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5518205165863037, 'eval_runtime': 111.2218, 'eval_samples_per_second': 1038.96, 'eval_steps_per_second': 32.476, 'epoch': 5.0}\n","{'loss': 1.5226, 'learning_rate': 0.0003702596053997923, 'epoch': 5.19}\n","{'loss': 1.5045, 'learning_rate': 0.0003616112841813776, 'epoch': 5.54}\n","{'loss': 1.5147, 'learning_rate': 0.0003529612322602977, 'epoch': 5.88}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"415600afd6d240859c8d1dc6ad23d61d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5410844087600708, 'eval_runtime': 110.5182, 'eval_samples_per_second': 1045.574, 'eval_steps_per_second': 32.682, 'epoch': 6.0}\n","{'loss': 1.4796, 'learning_rate': 0.0003443111803392177, 'epoch': 6.23}\n","{'loss': 1.4691, 'learning_rate': 0.00033566285912080306, 'epoch': 6.58}\n","{'loss': 1.4806, 'learning_rate': 0.0003270128071997231, 'epoch': 6.92}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24936038d4604258995294a894a74a81","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5386500358581543, 'eval_runtime': 111.3905, 'eval_samples_per_second': 1037.386, 'eval_steps_per_second': 32.426, 'epoch': 7.0}\n","{'loss': 1.4402, 'learning_rate': 0.0003183644859813084, 'epoch': 7.27}\n","{'loss': 1.4401, 'learning_rate': 0.00030971443406022846, 'epoch': 7.62}\n","{'loss': 1.4494, 'learning_rate': 0.0003010661128418138, 'epoch': 7.96}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a09b58e92a934e4885c7f12f79d69c08","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5290231704711914, 'eval_runtime': 110.3255, 'eval_samples_per_second': 1047.401, 'eval_steps_per_second': 32.739, 'epoch': 8.0}\n","{'loss': 1.4062, 'learning_rate': 0.00029241606092073383, 'epoch': 8.31}\n","{'loss': 1.4092, 'learning_rate': 0.00028376600899965385, 'epoch': 8.65}\n","{'loss': 1.4206, 'learning_rate': 0.0002751159570785739, 'epoch': 9.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dd6107f4bee44831a972ed6298455fd4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5234870910644531, 'eval_runtime': 110.4531, 'eval_samples_per_second': 1046.19, 'eval_steps_per_second': 32.702, 'epoch': 9.0}\n","{'loss': 1.3728, 'learning_rate': 0.00026646590515749395, 'epoch': 9.35}\n","{'loss': 1.3838, 'learning_rate': 0.0002578175839390793, 'epoch': 9.69}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7ea5a1d68f394db29ef781de09f0be50","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5168672800064087, 'eval_runtime': 110.7633, 'eval_samples_per_second': 1043.26, 'eval_steps_per_second': 32.61, 'epoch': 10.0}\n","{'loss': 1.3847, 'learning_rate': 0.0002491675320179993, 'epoch': 10.04}\n","{'loss': 1.346, 'learning_rate': 0.00024051921079958465, 'epoch': 10.38}\n","{'loss': 1.3567, 'learning_rate': 0.0002318674281758394, 'epoch': 10.73}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e42fa72e860f41f0b77ded2a705bf6a3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5134544372558594, 'eval_runtime': 110.6393, 'eval_samples_per_second': 1044.43, 'eval_steps_per_second': 32.647, 'epoch': 11.0}\n","{'loss': 1.3543, 'learning_rate': 0.00022321737625475945, 'epoch': 11.08}\n","{'loss': 1.3214, 'learning_rate': 0.00021456732433367947, 'epoch': 11.42}\n","{'loss': 1.3333, 'learning_rate': 0.00020591727241259952, 'epoch': 11.77}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e86475daed9489596d3c9751e0c9208","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5121747255325317, 'eval_runtime': 111.8382, 'eval_samples_per_second': 1033.234, 'eval_steps_per_second': 32.297, 'epoch': 12.0}\n","{'loss': 1.3223, 'learning_rate': 0.0001972654897888543, 'epoch': 12.11}\n","{'loss': 1.2992, 'learning_rate': 0.00018861543786777432, 'epoch': 12.46}\n","{'loss': 1.3096, 'learning_rate': 0.0001799636552440291, 'epoch': 12.81}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7cdbde08a78f4aa29adced74702eb46c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5109244585037231, 'eval_runtime': 110.6252, 'eval_samples_per_second': 1044.563, 'eval_steps_per_second': 32.651, 'epoch': 13.0}\n","{'loss': 1.2923, 'learning_rate': 0.0001713136033229491, 'epoch': 13.15}\n","{'loss': 1.2769, 'learning_rate': 0.00016266355140186916, 'epoch': 13.5}\n","{'loss': 1.2873, 'learning_rate': 0.0001540117687781239, 'epoch': 13.85}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe6af49f0ab340c890d7413fd776c11f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5143696069717407, 'eval_runtime': 111.7614, 'eval_samples_per_second': 1033.944, 'eval_steps_per_second': 32.319, 'epoch': 14.0}\n","{'loss': 1.2692, 'learning_rate': 0.00014536171685704396, 'epoch': 14.19}\n","{'loss': 1.2586, 'learning_rate': 0.0001367099342332987, 'epoch': 14.54}\n","{'loss': 1.2613, 'learning_rate': 0.00012805988231221876, 'epoch': 14.88}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b784fd89167413aa174fc5774b17dcf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5109548568725586, 'eval_runtime': 111.1046, 'eval_samples_per_second': 1040.056, 'eval_steps_per_second': 32.51, 'epoch': 15.0}\n","{'loss': 1.2446, 'learning_rate': 0.0001194115610938041, 'epoch': 15.23}\n","{'loss': 1.2351, 'learning_rate': 0.00011075977847005884, 'epoch': 15.58}\n","{'loss': 1.2438, 'learning_rate': 0.00010210972654897889, 'epoch': 15.92}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef0e00c99906490ebc99c4d6c6fe39d2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5105900764465332, 'eval_runtime': 111.1436, 'eval_samples_per_second': 1039.691, 'eval_steps_per_second': 32.498, 'epoch': 16.0}\n","{'loss': 1.2185, 'learning_rate': 9.345794392523364e-05, 'epoch': 16.27}\n","{'loss': 1.2178, 'learning_rate': 8.480962270681896e-05, 'epoch': 16.61}\n","{'loss': 1.2216, 'learning_rate': 7.615957078573901e-05, 'epoch': 16.96}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3daadc551534fc884e60d4f61660db5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.517675757408142, 'eval_runtime': 112.2189, 'eval_samples_per_second': 1029.729, 'eval_steps_per_second': 32.187, 'epoch': 17.0}\n","{'loss': 1.199, 'learning_rate': 6.750951886465906e-05, 'epoch': 17.31}\n","{'loss': 1.1966, 'learning_rate': 5.88594669435791e-05, 'epoch': 17.65}\n","{'loss': 1.2049, 'learning_rate': 5.020768431983385e-05, 'epoch': 18.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d09a58dd0e734e609166e3cc4fcf61a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5149683952331543, 'eval_runtime': 112.6942, 'eval_samples_per_second': 1025.385, 'eval_steps_per_second': 32.051, 'epoch': 18.0}\n","{'loss': 1.1824, 'learning_rate': 4.155936310141918e-05, 'epoch': 18.35}\n","{'loss': 1.1823, 'learning_rate': 3.290758047767393e-05, 'epoch': 18.69}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94ec412e529b45fe978f81b0bfaa2533","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.518808364868164, 'eval_runtime': 92.0118, 'eval_samples_per_second': 1255.872, 'eval_steps_per_second': 39.256, 'epoch': 19.0}\n","{'loss': 1.1836, 'learning_rate': 2.4257528556593975e-05, 'epoch': 19.04}\n","{'loss': 1.1723, 'learning_rate': 1.5607476635514018e-05, 'epoch': 19.38}\n","{'loss': 1.1693, 'learning_rate': 6.95742471443406e-06, 'epoch': 19.73}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8010ca7327c541ca9853e407090a3d7c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3612 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 1.5204483270645142, 'eval_runtime': 91.1479, 'eval_samples_per_second': 1267.775, 'eval_steps_per_second': 39.628, 'epoch': 20.0}\n","{'train_runtime': 33602.6877, 'train_samples_per_second': 275.11, 'train_steps_per_second': 8.598, 'train_loss': 1.406808580904941, 'epoch': 20.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=288900, training_loss=1.406808580904941, metrics={'train_runtime': 33602.6877, 'train_samples_per_second': 275.11, 'train_steps_per_second': 8.598, 'train_loss': 1.406808580904941, 'epoch': 20.0})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# saving model\n","trainer.save_model(save_model_path)"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["# loading the model and run inference for it\n","# model = AutoModelForSeq2SeqLM.from_pretrained(save_model_path)\n","model = AutoModelForSeq2SeqLM.from_pretrained('../models backup/t5_detoxifier-10')\n","model.eval()\n","model.config.use_cache = False"]},{"cell_type":"markdown","metadata":{},"source":["# Testing ??"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["def translate(model, inference_request, tokenizer=tokenizer):\n","    tokenized = tokenizer.encode(inference_request, return_tensors=\"pt\")\n","    outputs = model.generate(tokenized, generation_config=genConfig)\n","    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["This guy is a con, he's an actor, he's just a character.\n"]}],"source":["inference_request = \"\"\"\n","this guy is a con man. He's an actor. He's just a character.\n","\"\"\"\n","translate(model, inference_request)"]},{"cell_type":"markdown","metadata":{},"source":["# Validation ????"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from src.models.t5_toxicity_evaluator import T5TEModel\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","evalutator = T5TEModel('../models/last_toxic_regressor/model.pt').to(device)\n","model.to(device)\n","_ = evalutator.model.eval()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["eval_dataset = load_toxicity_dataset(**dataset_kwargs)\n","eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=128, shuffle=False, collate_fn=evalutator.collate_batch)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b5498cc5f7d4fd8a955d74b59fe13a4","version_major":2,"version_minor":0},"text/plain":["Translating:   0%|          | 0/452 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]}],"source":["from tqdm.auto import tqdm\n","transformed = []\n","\n","for batch in tqdm(eval_loader, total=len(eval_loader), desc='Translating'):\n","    output = model.generate(input_ids=batch.input_ids, attention_mask=batch.attention_mask, generation_config=genConfig)\n","    transformed += output.detach().cpu()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6125139129804d19b8ecfdb237b35585","version_major":2,"version_minor":0},"text/plain":["Evaluation:   0%|          | 0/452 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["ref_evaluations = []\n","\n","torch.cuda.empty_cache()\n","for batch in tqdm(eval_loader, total=len(eval_loader), desc='Evaluation'):\n","    output = evalutator(batch)\n","    ref_evaluations += output.detach().cpu()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["transformed_keys = [{'input_ids': x} for x in transformed]\n","trn_loader = torch.utils.data.DataLoader(transformed_keys, batch_size=128, shuffle=False, collate_fn=evalutator.collate_batch)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cccd4f9606c74cd58acf778cb0f7715b","version_major":2,"version_minor":0},"text/plain":["Evaluation:   0%|          | 0/452 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trn_evaluations = []\n","\n","torch.cuda.empty_cache()\n","for batch in tqdm(trn_loader, total=len(trn_loader), desc='Evaluation'):\n","    output = evalutator(batch)\n","    trn_evaluations += output.detach().cpu()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["threshold = 0.5\n","\n","refevs = np.array(ref_evaluations)\n","trnevs = np.array(trn_evaluations)\n","\n","ref_toxs = refevs > threshold\n","trn_toxs = trnevs > threshold"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Neutral -> neutral: 27871 -> 27857\n","Neutral -> toxic: 27871 -> 14\n","Toxic -> neutral: 29906 -> 28996\n","Toxic -> toxic: 29906 -> 910\n"]}],"source":["ref_neutrals = ref_toxs == False\n","ref_toxics = ref_toxs == True\n","trn_neutrals = trn_toxs == False\n","trn_toxics = trn_toxs == True\n","\n","print(f'Neutral -> neutral: {np.sum(ref_neutrals)} -> {np.sum(np.logical_and(ref_neutrals, trn_neutrals))}')\n","print(f'Neutral -> toxic: {np.sum(ref_neutrals)} -> {np.sum(np.logical_and(ref_neutrals, trn_toxics))}')\n","print(f'Toxic -> neutral: {np.sum(ref_toxics)} -> {np.sum(np.logical_and(ref_toxics, trn_neutrals))}')\n","print(f'Toxic -> toxic: {np.sum(ref_toxics)} -> {np.sum(np.logical_and(ref_toxics, trn_toxics))}')"]}],"metadata":{"colab":{"name":"Translation","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
