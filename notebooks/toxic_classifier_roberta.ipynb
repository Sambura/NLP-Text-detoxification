{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# my imports\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from src.data.load_data import load_tokenized_data\n",
    "from src.models.roberta_toxicity_classifier import RTCModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.656709671020508, -4.911500453948975]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RTCModel()\n",
    "\n",
    "model('you are amazing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_tokenized_data(path='../data/raw/filtered.tsv',\n",
    "                         cache_path='../data/processed/tokenized_roberta.tsv',\n",
    "                         tokenizer=model.tokenizer, \n",
    "                         flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.raw_data = dataframe\n",
    "\n",
    "        self.texts = dataframe['text'].tolist()\n",
    "        self.targets = dataframe['toxicity'].tolist()\n",
    "\n",
    "        self.inputs = []\n",
    "        for input, target in zip(self.texts, self.targets):\n",
    "            model_input = { 'input_ids': input, 'labels': target }\n",
    "            self.inputs.append(model_input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ToxicDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c24781d0c7440089590a248771dc449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1155554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`I'm not gonna have a child......with the same genetic disorder as me who's gonna die. L...`: output [0.8488573431968689, 0.15114262700080872] vs. label 0.95\n",
      "`Briggs, what the hell is going on?`: output [0.5176685452461243, 0.48233142495155334] vs. label 0.84\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "softmax = nn.Softmax(1)\n",
    "for sample in tqdm(dataset, total=len(dataset)):\n",
    "    if count > 10: break\n",
    "    logits = model(torch.tensor(sample['input_ids']).reshape(1, -1)).logits\n",
    "    output = softmax(logits)\n",
    "\n",
    "    roberta_toxic = output[0, 1] > output[0, 0]\n",
    "    label_toxic = sample['labels'] > 0.5\n",
    "    count += 1\n",
    "\n",
    "    if roberta_toxic ^ label_toxic:\n",
    "        text = tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True)\n",
    "        readable_output = output.detach().numpy().tolist()[0]\n",
    "        print(f'`{text}`: output {readable_output} vs. label {sample[\"labels\"]:0.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* threshold: 0.5; discrepancy: 13.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1f6a90477b4e858d4f11ebfe7129ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/36112 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\Documents\\GitHub\\PMLDL assignment 1 - Text detoxification\\notebooks\\toxic_classifier_roberta.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/PMLDL%20assignment%201%20-%20Text%20detoxification/notebooks/toxic_classifier_roberta.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m logits \u001b[39m=\u001b[39m model(samples)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/PMLDL%20assignment%201%20-%20Text%20detoxification/notebooks/toxic_classifier_roberta.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m roberta_toxic \u001b[39m=\u001b[39m logits[:, \u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m logits[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/PMLDL%20assignment%201%20-%20Text%20detoxification/notebooks/toxic_classifier_roberta.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m label_toxic \u001b[39m=\u001b[39m samples[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device) \u001b[39m>\u001b[39m toxicity_threshold\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/PMLDL%20assignment%201%20-%20Text%20detoxification/notebooks/toxic_classifier_roberta.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m total_discrepancy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(roberta_toxic \u001b[39m^\u001b[39m label_toxic)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/Documents/GitHub/PMLDL%20assignment%201%20-%20Text%20detoxification/notebooks/toxic_classifier_roberta.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(samples\u001b[39m.\u001b[39minput_ids)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\cuda_transformers_temp\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:242\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39m    `bool`: Indicate whether this [`BatchEncoding`] was generated from the result of a [`PreTrainedTokenizerFast`]\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m    or not.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encodings \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, item: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Any, EncodingFast]:\n\u001b[0;32m    243\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39m    If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m    etc.).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39m    with the constraint of slice.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, \u001b[39mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=False, collate_fn=model.collate_batch)\n",
    "\n",
    "total_discrepancy = 0\n",
    "total = 0\n",
    "toxicity_threshold = 0.5\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "with tqdm(dataloader, total=len(dataloader), desc='Evaluating') as pb:\n",
    "    for samples in pb:\n",
    "        logits = model(samples)\n",
    "\n",
    "        roberta_toxic = logits[:, 1] > logits[:, 0]\n",
    "        label_toxic = samples['labels'].to(device) > toxicity_threshold\n",
    "\n",
    "        total_discrepancy += torch.sum(roberta_toxic ^ label_toxic).item()\n",
    "        total += len(samples.input_ids)\n",
    "\n",
    "        pb.set_postfix({'Discrepancy': total_discrepancy / total})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_transformers_temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
